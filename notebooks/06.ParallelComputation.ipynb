{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallel Computation\n",
    "\n",
    "## Parallel computers\n",
    "- Multiprocessor/multicore: several processors work on data stored in shared memory\n",
    "- Cluster: several processor/memory units work together by exchanging data over a network\n",
    "- Co-processor: a general-purpose processor delegates specific tasks to a special-purpose processor (GPU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Programming\n",
    "- Decomposition of the complete task into independent subtasks and the data flow between them.\n",
    "- Distribution of the subtasks over the processors minimizing the total execution time.\n",
    "- For clusters: distribution of the data over the nodes minimizing the communication time.\n",
    "- For multiprocessors: optimization of the memory access patterns minimizing waiting times.\n",
    "- Synchronization of the individual processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import sleep\n",
    "def f(x):\n",
    "    sleep(1)\n",
    "    return x*x\n",
    "L = list(range(8))\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sum([f(x) for x in L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sum(map(f,L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiprocessing \n",
    "\n",
    "`multiprocessing` is a package that supports spawning processes.\n",
    "\n",
    "We can use it to display how many concurrent processes you can launch on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Futures\n",
    "\n",
    "The `concurrent.futures` module provides a high-level interface for asynchronously executing callables.\n",
    "\n",
    "The asynchronous execution can be performed with:\n",
    "- **threads**, using ThreadPoolExecutor, \n",
    "- separate **processes**, using ProcessPoolExecutor. \n",
    "Both implement the same interface, which is defined by the abstract Executor class.\n",
    "\n",
    "`concurrent.futures` can't launch **processes** on windows. Windows users must install \n",
    "[loky](https://github.com/tomMoral/loky)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "Wall time: 2.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#from concurrent.futures import ProcessPoolExecutor # for Unix\n",
    "from loky import ProcessPoolExecutor  # for Windows users\n",
    "\n",
    "with ProcessPoolExecutor() as epool: # Create several Python processes (cpu_count)\n",
    "\n",
    "    results = sum(epool.map(f, L))\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- `ProcessPoolExecutor` launches one slave process per physical core on the computer. \n",
    "- `epool.map` divides the input list into chunks and puts the tasks (function + chunk) on a queue.\n",
    "- Each slave process takes a task (function + a chunk of data), runs map(function, chunk), and puts the result on a result list.\n",
    "- `epool.map` on the master process waits until all tasks are handled and returns the concatenation of the result lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor() as epool:\n",
    "\n",
    "    results = sum(epool.map(f, L))\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thread and Process: Differences\n",
    "\n",
    "- A **process** is an instance of a running program. \n",
    "- **Process** may contain one or more **threads**, but a **thread** cannot contain a **process**.\n",
    "- **Process** has a self-contained execution environment. It has its own memory space. \n",
    "- Application running on your computer may be a set of cooperating **processes**.\n",
    "- **Process** don't share its memory, communication between **processes** implies data serialization.\n",
    "\n",
    "- A **thread** is made of and exist within a **process**; every **process** has at least one **thread**. \n",
    "- Multiple **threads** in a **process** share resources, which helps in efficient communication between **threads**.\n",
    "- **Threads** can be concurrent on a multi-core system, with every core executing the separate **threads** simultaneously.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Global Interpreter Lock (GIL)\n",
    "\n",
    "- The Python interpreter is not thread safe.\n",
    "- A few critical internal data structures may only be accessed by one thread at a time. Access to them is protected by the GIL.\n",
    "- Attempts at removing the GIL from Python have failed until now. The main difficulty is maintaining the C API for extension modules.\n",
    "- Multiprocessing avoids the GIL by having separate processes which each have an independent copy of the interpreter data structures.\n",
    "- The price to pay: serialization of tasks, arguments, and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Weighted mean and Variance\n",
    "\n",
    "### Exercise 6.1\n",
    "\n",
    "Use `ThreadPoolExecutor` to parallelized functions written in notebook 05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wordcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "## Parallel map\n",
    "\n",
    "\n",
    "- Let's improve the `mapper` function by print out inside the function the current process name. \n",
    "\n",
    "*Example*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from loky import ProcessPoolExecutor \n",
    "def process_name(n):\n",
    "    \" prints out the current process name \"\n",
    "    print(mp.current_process().name)\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=4) as e:\n",
    "    _ = e.map(process_name, range(mp.cpu_count()))\n",
    "process_name(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 6.2\n",
    "\n",
    "- Modify the mapper function by adding this print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "\n",
    "def mapper(filename):\n",
    "    \"\"\"Function with a single file name as input that returns a sorted sequence of tuples (word, 1) values.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "    word_list = sorted(text.lower().replace('.', '').split())\n",
    "    print(mp.current_process().name) # Rien ne s'affiche avec ProcessPoolExecutor\n",
    "    return [(word, 1) for word in word_list]\n",
    "\n",
    "def partitioner(mapper_res):\n",
    "    \"\"\"Function that stores the key/value pairs from mapper that group (word, 1) pairs into a list\n",
    "    of format (word, [1, 1, 1, ...] with n times 1, n is the number of occurences of word)\"\"\"\n",
    "    word_dict = defaultdict(list)\n",
    "    for word, occ in mapper_res:\n",
    "        word_dict[word].append(occ)\n",
    "    return sorted(list(word_dict.items()))\n",
    "\n",
    "def reducer(partition_elmt):\n",
    "    \"\"\"Function that read a tuple (word,[1,1,1,..,1]) and sum the occurrences of word to a final count,\n",
    "    and then output the tuple (word,occurences).\"\"\"\n",
    "    return (partition_elmt[0], len(partition_elmt[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel reduce\n",
    "\n",
    "- For parallel reduce operation, data must be aligned in a container. We already created a `partitioner` function that returns this container.\n",
    "\n",
    "### Exercise 6.3\n",
    "\n",
    "Write a parallel program that uses the three functions above using `ProcessPoolExecutor`. It reads all the \"sample\\*.txt\" files. Map and reduce steps are parallel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample00.txt',\n",
       " 'sample01.txt',\n",
       " 'sample02.txt',\n",
       " 'sample03.txt',\n",
       " 'sample04.txt',\n",
       " 'sample05.txt',\n",
       " 'sample06.txt',\n",
       " 'sample07.txt']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lorem import text\n",
    "for i in range(8):\n",
    "    with open(\"sample{0:02d}.txt\".format(i), \"w\") as f:\n",
    "        f.write(text())\n",
    "        \n",
    "import glob\n",
    "files = glob.glob('sample0*.txt')\n",
    "files        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('labore', 68),\n",
       " ('tempora', 67),\n",
       " ('consectetur', 66),\n",
       " ('neque', 66),\n",
       " ('magnam', 65),\n",
       " ('est', 64),\n",
       " ('porro', 63),\n",
       " ('voluptatem', 63),\n",
       " ('dolor', 62),\n",
       " ('amet', 61),\n",
       " ('dolorem', 61),\n",
       " ('ipsum', 61),\n",
       " ('modi', 61),\n",
       " ('adipisci', 60),\n",
       " ('aliquam', 60),\n",
       " ('quaerat', 60),\n",
       " ('numquam', 59),\n",
       " ('sed', 59),\n",
       " ('dolore', 58),\n",
       " ('eius', 57),\n",
       " ('quisquam', 57),\n",
       " ('ut', 55),\n",
       " ('etincidunt', 53),\n",
       " ('quiquia', 52),\n",
       " ('non', 51),\n",
       " ('sit', 47),\n",
       " ('velit', 42)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from itertools import chain\n",
    "from loky import ProcessPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def wordcount(file_list):\n",
    "    \"\"\"Function taking for argument a list of files and returns the count (word, occurences)\n",
    "    of all files together sorted by the number of occurences\"\"\"\n",
    "    with ProcessPoolExecutor() as e:\n",
    "        mapped = e.map(mapper, file_list)\n",
    "        res = e.map(reducer, partitioner(chain(*mapped)))\n",
    "    return sorted(res, key=lambda t:t[1], reverse=True)\n",
    "\n",
    "wordcount(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Increase volume of data\n",
    "\n",
    "*Due to the proxy, code above is not runnable on workstations*\n",
    "\n",
    "### Getting the data\n",
    "\n",
    "- [The Latin Library](http://www.thelatinlibrary.com/) contains a huge collection of freely accessible Latin texts. We get links on the Latin Library's homepage ignoring some links that are not associated with a particular author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import *\n",
    "\n",
    "base_url = \"http://www.thelatinlibrary.com/\"\n",
    "home_content = urlopen(base_url)\n",
    "\n",
    "soup = BeautifulSoup(home_content, \"lxml\")\n",
    "author_page_links = soup.find_all(\"a\")\n",
    "author_pages = [ap[\"href\"] for i, ap in enumerate(author_page_links) if i < 49]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate html links\n",
    "\n",
    "- Create a list of all links pointing to Latin texts. The Latin Library uses a special format which makes it easy to find the corresponding links: All of these links contain the name of the text author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ap_content = list()\n",
    "for ap in author_pages:\n",
    "    ap_content.append(urlopen(base_url + ap))\n",
    "\n",
    "book_links = list()\n",
    "for path, content in zip(author_pages, ap_content):\n",
    "    author_name = path.split(\".\")[0]\n",
    "    ap_soup = BeautifulSoup(content, \"lxml\")\n",
    "    book_links += ([link for link in ap_soup.find_all(\"a\", {\"href\": True}) if author_name in link[\"href\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Download webpages content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to retrieve cicero/cael.shtml.\n",
      "Getting content 100 of 100\r"
     ]
    }
   ],
   "source": [
    "from urllib.error import HTTPError\n",
    "\n",
    "num_pages = 100\n",
    "\n",
    "for i, bl in enumerate(book_links[:num_pages]):\n",
    "    print(\"Getting content \" + str(i + 1) + \" of \" + str(num_pages), end=\"\\r\", flush=True)\n",
    "    try:\n",
    "        content = urlopen(base_url + bl[\"href\"]).read()\n",
    "        with open(\"book\" + str(i) + \".dat\",\"wb\") as f:\n",
    "            f.write(content)\n",
    "    except HTTPError as err:\n",
    "        print(\"Unable to retrieve \" + bl[\"href\"] + \".\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extract data files\n",
    "\n",
    "- I already put the content of pages in files named book-*.txt\n",
    "- You can extract data from the archive by running the cell below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os  # library to get directory and file paths\n",
    "import tarfile # this module makes possible to read and write tar archives\n",
    "\n",
    "def extract_data():\n",
    "    datadir = os.path.join('..','data','latinbooks')\n",
    "    if not os.path.exists(datadir):\n",
    "       print(\"Extracting data...\")\n",
    "       tar_path = os.path.join('..','data', 'latinbooks.tgz')\n",
    "       with tarfile.open(tar_path, mode='r:gz') as books:\n",
    "          books.extractall('../data')\n",
    "            \n",
    "extract_data() # this function call will extract text files in ../data/latinbooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Read data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "files = glob('../data/latinbooks/*')\n",
    "texts = list()\n",
    "for file in files:\n",
    "    with open(file,'rb') as f:\n",
    "        text = f.read()\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extract the text from html and split the text at periods to convert it into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adfirmant etiam aliqui terrarum halitu densiore crassatum aera emittendis corporis spiraminibus resistentem necare non nullos qua causa animalia praeter homines cetera iugiter prona homero auctore et experimentis deinceps multis cum talis incesserit labes ante novimus interire\n",
      "Wall time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sentences = list()\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    print(\"Document \" + str(i + 1) + \" of \" + str(len(texts)), end=\"\\r\", flush=True)\n",
    "    textSoup = BeautifulSoup(text, \"lxml\")\n",
    "    paragraphs = textSoup.find_all(\"p\", attrs={\"class\":None})\n",
    "    prepared = (\"\".join([p.text.strip().lower() for p in paragraphs[1:-1]]))\n",
    "    for t in prepared.split(\".\"):\n",
    "        part = \"\".join([c for c in t if c.isalpha() or c.isspace()])\n",
    "        sentences.append(part.strip())\n",
    "\n",
    "print(sentences[1262])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31767"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 6.4\n",
    "\n",
    "Parallelize this last process using `concurrent.futures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from loky import ProcessPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from itertools import chain\n",
    "\n",
    "def mapper(text):\n",
    "    textSoup = BeautifulSoup(text, \"lxml\")\n",
    "    paragraphs = textSoup.find_all(\"p\", attrs={\"class\":None})\n",
    "    prepared = (\"\".join([p.text.strip().lower() for p in paragraphs[1:-1]]))\n",
    "    sentences = []\n",
    "    for t in prepared.split(\".\"):\n",
    "        part = \"\".join([c for c in t if c.isalpha() or c.isspace()])\n",
    "        sentences.append(part.strip())\n",
    "    return(sentences)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    mapped = executor.map(mapper, texts)\n",
    "    \n",
    "sentences2 = [values for values in mapped]\n",
    "sentences2 = list(chain(*sentences2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adfirmant etiam aliqui terrarum halitu densiore crassatum aera emittendis corporis spiraminibus resistentem necare non nullos qua causa animalia praeter homines cetera iugiter prona homero auctore et experimentis deinceps multis cum talis incesserit labes ante novimus interire\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31767"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentences2[1262])\n",
    "len(sentences2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "- [Using Conditional Random Fields and Python for Latin word segmentation](https://medium.com/@felixmohr/using-python-and-conditional-random-fields-for-latin-word-segmentation-416ca7a9e513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test to better understand how it works\n",
    "\n",
    "from time import sleep\n",
    "import random\n",
    "import threading\n",
    "\n",
    "values = list(range(10))\n",
    "\n",
    "def f(x):\n",
    "    freeze_time = random.randint(2,4)\n",
    "    print(\"(\" + threading.current_thread().name + \") Waiting \" + str(freeze_time) + \" seconds for compute the square of \" + str(x))\n",
    "    sleep(freeze_time)\n",
    "    print(\"(\" + threading.current_thread().name + \") Done\")\n",
    "    return(x*x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(MainThread) Waiting 3 seconds for compute the square of 0\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 4 seconds for compute the square of 1\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 4 seconds for compute the square of 2\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 2 seconds for compute the square of 3\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 2 seconds for compute the square of 4\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 4 seconds for compute the square of 5\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 3 seconds for compute the square of 6\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 3 seconds for compute the square of 7\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 3 seconds for compute the square of 8\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 3 seconds for compute the square of 9\n",
      "(MainThread) Done\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = [f(x) for x in values]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(MainThread) Waiting 4 seconds for compute the square of 0\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 2 seconds for compute the square of 1\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 4 seconds for compute the square of 2\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 4 seconds for compute the square of 3\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 2 seconds for compute the square of 4\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 4 seconds for compute the square of 5\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 4 seconds for compute the square of 6\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 4 seconds for compute the square of 7\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 3 seconds for compute the square of 8\n",
      "(MainThread) Done\n",
      "(MainThread) Waiting 4 seconds for compute the square of 9\n",
      "(MainThread) Done\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "Wall time: 35.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = [i for i in map(f, values)]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Thread-186) Waiting 3 seconds for compute the square of 0\n",
      "(Thread-187) Waiting 3 seconds for compute the square of 1\n",
      "(Thread-188) Waiting 4 seconds for compute the square of 2\n",
      "(Thread-189) Waiting 2 seconds for compute the square of 3\n",
      "(Thread-189) Done\n",
      "(Thread-189) Waiting 4 seconds for compute the square of 4\n",
      "(Thread-186) Done(Thread-187) Done\n",
      "(Thread-186) Waiting 2 seconds for compute the square of 5\n",
      "\n",
      "(Thread-187) Waiting 4 seconds for compute the square of 6\n",
      "(Thread-188) Done\n",
      "(Thread-188) Waiting 4 seconds for compute the square of 7\n",
      "(Thread-186) Done\n",
      "(Thread-186) Waiting 3 seconds for compute the square of 8\n",
      "(Thread-189) Done\n",
      "(Thread-189) Waiting 4 seconds for compute the square of 9\n",
      "(Thread-187) Done\n",
      "(Thread-188) Done\n",
      "(Thread-186) Done\n",
      "(Thread-189) Done\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Avant de relancer ce code, il faut reancer la définition de la fonction f !!\n",
    "\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor: #Plus max_workers est grand, plus ca va vite\n",
    "    values = executor.map(f, values)\n",
    "res = [value for value in values]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 16, 81, 256, 625, 1296, 2401, 4096, 6561]\n",
      "Wall time: 4.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Avant de relancer ce code, il faut reancer la définition de la fonction f !!\n",
    "\n",
    "import multiprocessing as mp\n",
    "from loky import ProcessPoolExecutor\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=15) as executor: # Bizarrement on peut utiliser plus de process que cpu_count()\n",
    "    values = executor.map(f, values)\n",
    "res = [value for value in values]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
