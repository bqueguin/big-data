{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some recommendations:\n",
    "- *Don't google too much, ask me or use the python documentation through `help` function.*\n",
    "- *Do not try to find a clever or optimized solution, do something that works before.*\n",
    "- *Please don't get the solution from your colleagues*\n",
    "- *Notebooks will be updated next week with solutions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wordcount\n",
    "\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Word_count)\n",
    "\n",
    "- Word count example reads text files and counts how often words occur. \n",
    "- Word count is commonly used by translators to determine the price for the translation job.\n",
    "- This is the \"Hello World\" program of Big Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Create sample text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from lorem import text\n",
    "\n",
    "with open(\"sample.txt\", \"w\") as f:\n",
    "    f.write(text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.1\n",
    "\n",
    "Write a python program that counts the number of lines, words and characters in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [version 10.0.16299.665]\r\n",
      "(c) 2017 Microsoft Corporation. Tous droits réservés.\r\n",
      "\r\n",
      "(big-data) C:\\Users\\bruno\\Desktop\\S9\\Outils du Big Data\\big-data\\notebooks>echo \"Number of non-empty lines:\"\n",
      "\"Number of non-empty lines:\"\r\n",
      "\r\n",
      "(big-data) C:\\Users\\bruno\\Desktop\\S9\\Outils du Big Data\\big-data\\notebooks>find/v /c \"\" sample.txt\n",
      "\r\n",
      "---------- SAMPLE.TXT: 9\r\n",
      "\r\n",
      "(big-data) C:\\Users\\bruno\\Desktop\\S9\\Outils du Big Data\\big-data\\notebooks>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "echo \"Number of non-empty lines:\"\n",
    "find/v /c \"\" sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['testing.txt', 3, 4, 21]\n"
     ]
    }
   ],
   "source": [
    "def wc(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "        values = [filename, 1, 1, 0]\n",
    "        for i in text:\n",
    "            if i == '\\n':\n",
    "                values[1]+=1\n",
    "            if i == ' ':\n",
    "                values[2]+=1 # Problème: les mots en débuts de  nouvelles lignes ne sont pas comptabilisés\n",
    "            values[3]+=1\n",
    "    print(values)\n",
    "\n",
    "wc(\"testing.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['testing.txt', 3, 6, 21]\n",
      "['sample.txt', 9, 224, 1343]\n"
     ]
    }
   ],
   "source": [
    "def wc2(filename, without_spaces = False):\n",
    "    \"\"\" Take a file and print a list containing the following informations:\n",
    "    _ file name\n",
    "    _ number of lines\n",
    "    _ number of words\n",
    "    _ number of characters\n",
    "    \"\"\"\n",
    "    values = [filename, 0, 0, 0]\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        values[1] = len(lines)\n",
    "        values[2] = sum([len(line.split()) for line in lines])\n",
    "        if without_spaces:\n",
    "            values[3] = sum([sum([len(word) for word in line.split()]) for line in lines])\n",
    "        else:\n",
    "            values[3] = sum([len(line) for line in lines])\n",
    "    print(values)\n",
    "\n",
    "wc2(\"testing.txt\")\n",
    "wc2(\"sample.txt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function wc2 in module __main__:\n",
      "\n",
      "wc2(filename, without_spaces=False)\n",
      "    Take a file and print a list containing the following informations:\n",
      "    _ file name\n",
      "    _ number of lines\n",
      "    _ number of words\n",
      "    _ number of characters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(wc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.2\n",
    "\n",
    "Create a function called `wordcount` that take a file name as argument and return a lists containing all words as items.\n",
    "\n",
    "```pytb\n",
    "wordcount(\"sample.txt\")\n",
    "['labore', 'modi', 'ipsum', 'eius', 'eius', 'tempora', 'sed']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adipisci',\n",
       " 'adipisci',\n",
       " 'adipisci',\n",
       " 'adipisci',\n",
       " 'adipisci',\n",
       " 'adipisci',\n",
       " 'adipisci',\n",
       " 'aliquam',\n",
       " 'aliquam',\n",
       " 'aliquam',\n",
       " 'aliquam',\n",
       " 'aliquam',\n",
       " 'aliquam',\n",
       " 'aliquam',\n",
       " 'aliquam',\n",
       " 'aliquam',\n",
       " 'aliquam',\n",
       " 'amet',\n",
       " 'amet',\n",
       " 'amet',\n",
       " 'amet',\n",
       " 'amet',\n",
       " 'amet',\n",
       " 'amet',\n",
       " 'amet',\n",
       " 'consectetur',\n",
       " 'consectetur',\n",
       " 'consectetur',\n",
       " 'consectetur',\n",
       " 'consectetur',\n",
       " 'consectetur',\n",
       " 'consectetur',\n",
       " 'consectetur',\n",
       " 'consectetur',\n",
       " 'consectetur',\n",
       " 'consectetur',\n",
       " 'consectetur',\n",
       " 'dolor',\n",
       " 'dolor',\n",
       " 'dolor',\n",
       " 'dolor',\n",
       " 'dolor',\n",
       " 'dolor',\n",
       " 'dolor',\n",
       " 'dolore',\n",
       " 'dolore',\n",
       " 'dolore',\n",
       " 'dolore',\n",
       " 'dolore',\n",
       " 'dolore',\n",
       " 'dolorem',\n",
       " 'dolorem',\n",
       " 'dolorem',\n",
       " 'dolorem',\n",
       " 'dolorem',\n",
       " 'dolorem',\n",
       " 'dolorem',\n",
       " 'dolorem',\n",
       " 'eius',\n",
       " 'eius',\n",
       " 'eius',\n",
       " 'eius',\n",
       " 'eius',\n",
       " 'eius',\n",
       " 'est',\n",
       " 'est',\n",
       " 'est',\n",
       " 'est',\n",
       " 'est',\n",
       " 'est',\n",
       " 'est',\n",
       " 'est',\n",
       " 'est',\n",
       " 'est',\n",
       " 'est',\n",
       " 'est',\n",
       " 'etincidunt',\n",
       " 'etincidunt',\n",
       " 'etincidunt',\n",
       " 'etincidunt',\n",
       " 'etincidunt',\n",
       " 'ipsum',\n",
       " 'ipsum',\n",
       " 'ipsum',\n",
       " 'ipsum',\n",
       " 'labore',\n",
       " 'labore',\n",
       " 'labore',\n",
       " 'labore',\n",
       " 'labore',\n",
       " 'labore',\n",
       " 'labore',\n",
       " 'labore',\n",
       " 'labore',\n",
       " 'labore',\n",
       " 'labore',\n",
       " 'labore',\n",
       " 'magnam',\n",
       " 'magnam',\n",
       " 'magnam',\n",
       " 'magnam',\n",
       " 'magnam',\n",
       " 'magnam',\n",
       " 'magnam',\n",
       " 'magnam',\n",
       " 'magnam',\n",
       " 'magnam',\n",
       " 'magnam',\n",
       " 'magnam',\n",
       " 'modi',\n",
       " 'modi',\n",
       " 'modi',\n",
       " 'modi',\n",
       " 'modi',\n",
       " 'modi',\n",
       " 'modi',\n",
       " 'modi',\n",
       " 'modi',\n",
       " 'modi',\n",
       " 'modi',\n",
       " 'neque',\n",
       " 'neque',\n",
       " 'neque',\n",
       " 'neque',\n",
       " 'neque',\n",
       " 'neque',\n",
       " 'non',\n",
       " 'non',\n",
       " 'non',\n",
       " 'non',\n",
       " 'non',\n",
       " 'non',\n",
       " 'non',\n",
       " 'non',\n",
       " 'numquam',\n",
       " 'numquam',\n",
       " 'numquam',\n",
       " 'numquam',\n",
       " 'numquam',\n",
       " 'numquam',\n",
       " 'numquam',\n",
       " 'numquam',\n",
       " 'porro',\n",
       " 'porro',\n",
       " 'porro',\n",
       " 'porro',\n",
       " 'porro',\n",
       " 'porro',\n",
       " 'porro',\n",
       " 'porro',\n",
       " 'porro',\n",
       " 'quaerat',\n",
       " 'quaerat',\n",
       " 'quaerat',\n",
       " 'quaerat',\n",
       " 'quaerat',\n",
       " 'quaerat',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quiquia',\n",
       " 'quisquam',\n",
       " 'quisquam',\n",
       " 'sed',\n",
       " 'sed',\n",
       " 'sed',\n",
       " 'sed',\n",
       " 'sed',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'tempora',\n",
       " 'tempora',\n",
       " 'tempora',\n",
       " 'tempora',\n",
       " 'tempora',\n",
       " 'tempora',\n",
       " 'tempora',\n",
       " 'tempora',\n",
       " 'ut',\n",
       " 'ut',\n",
       " 'ut',\n",
       " 'ut',\n",
       " 'ut',\n",
       " 'ut',\n",
       " 'ut',\n",
       " 'ut',\n",
       " 'velit',\n",
       " 'velit',\n",
       " 'velit',\n",
       " 'velit',\n",
       " 'velit',\n",
       " 'velit',\n",
       " 'velit',\n",
       " 'velit',\n",
       " 'velit',\n",
       " 'velit',\n",
       " 'voluptatem',\n",
       " 'voluptatem',\n",
       " 'voluptatem',\n",
       " 'voluptatem',\n",
       " 'voluptatem',\n",
       " 'voluptatem',\n",
       " 'voluptatem',\n",
       " 'voluptatem',\n",
       " 'voluptatem']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wordcount(filename):\n",
    "    \"\"\"Function that takes a file name as argument\n",
    "    and return a lists containing all words as items in alphabetic order.\"\"\"\n",
    "    with open(filename, 'r') as f:       \n",
    "        text = f.read()\n",
    "        words = text.lower().replace('.', '').split()\n",
    "    return(sorted(words))\n",
    "    \n",
    "wordcount(\"sample.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sorting a dictionary by value\n",
    "\n",
    "By default, if you use `sorted` function on a `dict`, it will use keys to sort it.\n",
    "To sort by values, you can use [operator](https://docs.python.org/3.6/library/operator.html).itemgetter(1)\n",
    "Return a callable object that fetches item from its operand using the operand’s `__getitem__(` method. It could be used to sort results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 3, 'banana': 2, 'orange': 1, 'pear': 5}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "fruits = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]\n",
    "getcount = operator.itemgetter(1)\n",
    "dict(sorted(fruits, key=getcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`sorted` function has also a `reverse` optional argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 3, 'banana': 2, 'orange': 1, 'pear': 5}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(fruits, key=getcount, reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.3\n",
    "\n",
    "Modify the function `wordcount` to reduce the list of words and return a dictionary containing all words as keys and number of occurrences as values.\n",
    "\n",
    "```pybt\n",
    "wordcount('sample.txt')\n",
    "{'tempora': 2, 'non': 1, 'quisquam': 1, 'amet': 1, 'sit': 1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adipisci': 7,\n",
       " 'aliquam': 10,\n",
       " 'amet': 8,\n",
       " 'consectetur': 12,\n",
       " 'dolor': 7,\n",
       " 'dolore': 6,\n",
       " 'dolorem': 8,\n",
       " 'eius': 6,\n",
       " 'est': 12,\n",
       " 'etincidunt': 5,\n",
       " 'ipsum': 4,\n",
       " 'labore': 12,\n",
       " 'magnam': 12,\n",
       " 'modi': 11,\n",
       " 'neque': 6,\n",
       " 'non': 8,\n",
       " 'numquam': 8,\n",
       " 'porro': 9,\n",
       " 'quaerat': 6,\n",
       " 'quiquia': 13,\n",
       " 'quisquam': 2,\n",
       " 'sed': 5,\n",
       " 'sit': 12,\n",
       " 'tempora': 8,\n",
       " 'ut': 8,\n",
       " 'velit': 10,\n",
       " 'voluptatem': 9}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce2(word_list):\n",
    "    \"\"\"Function that takes a list of words IN ALPHABETIC ORDER as argument and\n",
    "    returns a dictionary containing all words as keys and number of occurrences as values\"\"\"\n",
    "    word_dict = {}\n",
    "    last_word = None\n",
    "    for word in word_list:\n",
    "        if word != last_word:\n",
    "            word_dict[word] = 1\n",
    "            last_word = word\n",
    "        else:\n",
    "            word_dict[word] += 1\n",
    "    return word_dict\n",
    "    #return sorted(word_dict.items(), reverse=True, key=operator.itemgetter(1))\n",
    "    #return sorted(word_dict.items(), reverse=True, key=lambda t:t[1])\n",
    "    \n",
    "    \n",
    "reduce(wordcount(\"sample.txt\"))\n",
    "#sum(reduce(wordcount(\"sample.txt\")).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adipisci': 7,\n",
       " 'aliquam': 10,\n",
       " 'amet': 8,\n",
       " 'consectetur': 12,\n",
       " 'dolor': 7,\n",
       " 'dolore': 6,\n",
       " 'dolorem': 8,\n",
       " 'eius': 6,\n",
       " 'est': 12,\n",
       " 'etincidunt': 5,\n",
       " 'ipsum': 4,\n",
       " 'labore': 12,\n",
       " 'magnam': 12,\n",
       " 'modi': 11,\n",
       " 'neque': 6,\n",
       " 'non': 8,\n",
       " 'numquam': 8,\n",
       " 'porro': 9,\n",
       " 'quaerat': 6,\n",
       " 'quiquia': 13,\n",
       " 'quisquam': 2,\n",
       " 'sed': 5,\n",
       " 'sit': 12,\n",
       " 'tempora': 8,\n",
       " 'ut': 8,\n",
       " 'velit': 10,\n",
       " 'voluptatem': 9}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce(word_list):\n",
    "    \"\"\"Function that takes a list of words as argument and\n",
    "    returns a dictionary containing all words as keys and number of occurrences as values\"\"\"\n",
    "    word_dict = {}\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            word_dict[word] += 1\n",
    "        except KeyError:\n",
    "            word_dict[word] = 1\n",
    "    return word_dict\n",
    "\n",
    "reduce2(wordcount(\"sample.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You probably notice that these two simple functions are not easy to implement. Python standard library provides some features that can help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Container datatypes\n",
    "\n",
    "`collection` module implements specialized container datatypes providing alternatives to Python’s general purpose built-in containers, `dict`, `list`, `set`, and `tuple`.\n",
    "\n",
    "- `defaultdict` :\tdict subclass that calls a factory function to supply missing values\n",
    "- `Counter`\t: dict subclass for counting hashable objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## defaultdict\n",
    "\n",
    "When you implement the `reduce` function you probably add some probleme to append key-value pair to your `dict`. If you try to change the value of a key that is not present \n",
    "in the dict, the key is not automatically created.\n",
    "\n",
    "The `defaultdict` is the solution. This container is a `dict` subclass that calls a factory function to supply missing values.\n",
    "For example, using list as the default_factory, it is easy to group a sequence of key-value pairs into a dictionary of lists:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.4\n",
    "\n",
    "- Modify the reduce part of `wordcount` function you wrote above by using a defaultdict with the most suitable factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue': [2, 4], 'red': [1], 'yellow': [1, 3]}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]\n",
    "d = defaultdict(list)\n",
    "for k, v in s:\n",
    "    d[k].append(v)\n",
    "\n",
    "dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adipisci': 7,\n",
       " 'aliquam': 10,\n",
       " 'amet': 8,\n",
       " 'consectetur': 12,\n",
       " 'dolor': 7,\n",
       " 'dolore': 6,\n",
       " 'dolorem': 8,\n",
       " 'eius': 6,\n",
       " 'est': 12,\n",
       " 'etincidunt': 5,\n",
       " 'ipsum': 4,\n",
       " 'labore': 12,\n",
       " 'magnam': 12,\n",
       " 'modi': 11,\n",
       " 'neque': 6,\n",
       " 'non': 8,\n",
       " 'numquam': 8,\n",
       " 'porro': 9,\n",
       " 'quaerat': 6,\n",
       " 'quiquia': 13,\n",
       " 'quisquam': 2,\n",
       " 'sed': 5,\n",
       " 'sit': 12,\n",
       " 'tempora': 8,\n",
       " 'ut': 8,\n",
       " 'velit': 10,\n",
       " 'voluptatem': 9}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def reduce3(word_list):\n",
    "    word_dict = defaultdict(int)\n",
    "    for word in word_list:\n",
    "        word_dict[word] += 1\n",
    "    return(dict(word_dict))\n",
    "\n",
    "reduce3(wordcount(\"sample.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Counter\n",
    "\n",
    "A Counter is a dict subclass for counting hashable objects. It is an unordered collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts.\n",
    "\n",
    "Elements are counted from an iterable or initialized from another mapping (or counter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'g': 13, 'b': 23, 'r': 23}\n",
      "0\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "violet = dict(r=23,g=13,b=23)\n",
    "print(violet)\n",
    "cnt = Counter(violet)  # or Counter(r=238, g=130, b=238)\n",
    "print(cnt['c'])\n",
    "print(cnt['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g g g g g g g g g g g g g b b b b b b b b b b b b b b b b b b b b b b b r r r r r r r r r r r r r r r r r r r r r r r\n"
     ]
    }
   ],
   "source": [
    "print(*cnt.elements())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 23), ('r', 23)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([13, 23, 23])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.5\n",
    "\n",
    "Use a `Counter` object to count words occurences in the sample text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adipisci': 7,\n",
       " 'aliquam': 10,\n",
       " 'amet': 8,\n",
       " 'consectetur': 12,\n",
       " 'dolor': 7,\n",
       " 'dolore': 6,\n",
       " 'dolorem': 8,\n",
       " 'eius': 6,\n",
       " 'est': 12,\n",
       " 'etincidunt': 5,\n",
       " 'ipsum': 4,\n",
       " 'labore': 12,\n",
       " 'magnam': 12,\n",
       " 'modi': 11,\n",
       " 'neque': 6,\n",
       " 'non': 8,\n",
       " 'numquam': 8,\n",
       " 'porro': 9,\n",
       " 'quaerat': 6,\n",
       " 'quiquia': 13,\n",
       " 'quisquam': 2,\n",
       " 'sed': 5,\n",
       " 'sit': 12,\n",
       " 'tempora': 8,\n",
       " 'ut': 8,\n",
       " 'velit': 10,\n",
       " 'voluptatem': 9}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def reduce4(word_list):\n",
    "    cnt = Counter(word_list)\n",
    "    return dict(cnt)\n",
    "\n",
    "reduce4(wordcount(\"sample.txt\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The Counter class is similar to bags or multisets in some Python libraries or other languages. We will see later how to use Counter-like objects in a parallel context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Process two files\n",
    "\n",
    "- Create two files containing `lorem` text named 'sample1.txt' and 'sample2.txt'\n",
    "- If you process these two files you get two dictionaries.\n",
    "- You have to loop over them to sum occurences and return the reslulted dict. To iterate on specific mappings, Python standard library provides some useful feartures in `itertools` module.\n",
    "- [itertools.chain(*mapped_values)](https://docs.python.org/3.6/library/itertools.html#itertools.chain) could be used for treating consecutive sequences as a single sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 3,\n",
       " 'banana': 2,\n",
       " 'carrot': 4,\n",
       " 'celery': 5,\n",
       " 'endive': 2,\n",
       " 'orange': 1,\n",
       " 'pear': 5,\n",
       " 'spinach': 1}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools, operator\n",
    "fruits = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]\n",
    "vegetables = [('endive', 2), ('spinach', 1), ('celery', 5), ('carrot', 4)]\n",
    "getcount = operator.itemgetter(1)\n",
    "dict(sorted(itertools.chain(fruits,vegetables), key=getcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.6\n",
    "\n",
    "- Write the program that creates both files, processes and use `itertools.chain` to get the merged word count dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de 2 nouveaux fichiers textes\n",
    "\n",
    "from lorem import text\n",
    "\n",
    "with open('sample1.txt', 'w') as f:\n",
    "    f.write(text())\n",
    "with open('sample2.txt', 'w') as f:\n",
    "    f.write(text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adipisci': 6,\n",
       " 'aliquam': 19,\n",
       " 'amet': 14,\n",
       " 'consectetur': 10,\n",
       " 'dolor': 16,\n",
       " 'dolore': 12,\n",
       " 'dolorem': 16,\n",
       " 'eius': 12,\n",
       " 'est': 13,\n",
       " 'etincidunt': 15,\n",
       " 'ipsum': 15,\n",
       " 'labore': 16,\n",
       " 'magnam': 13,\n",
       " 'modi': 8,\n",
       " 'neque': 15,\n",
       " 'non': 7,\n",
       " 'numquam': 11,\n",
       " 'porro': 16,\n",
       " 'quaerat': 18,\n",
       " 'quiquia': 21,\n",
       " 'quisquam': 9,\n",
       " 'sed': 4,\n",
       " 'sit': 15,\n",
       " 'tempora': 14,\n",
       " 'ut': 5,\n",
       " 'velit': 20,\n",
       " 'voluptatem': 18}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def wordcount_two_files(filename1, filename2):\n",
    "    \"\"\"Function that takes 2 file names as argument\n",
    "    and return a lists containing all words as items in alphabetic order of the two files.\"\"\"\n",
    "    word_list1 = wordcount(filename1)\n",
    "    word_list2 = wordcount(filename2)\n",
    "    return sorted(word_list1 + word_list2)\n",
    "\n",
    "reduce(wordcount_two_files(\"sample1.txt\", \"sample2.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adipisci': 6,\n",
       " 'aliquam': 19,\n",
       " 'amet': 14,\n",
       " 'consectetur': 10,\n",
       " 'dolor': 16,\n",
       " 'dolore': 12,\n",
       " 'dolorem': 16,\n",
       " 'eius': 12,\n",
       " 'est': 13,\n",
       " 'etincidunt': 15,\n",
       " 'ipsum': 15,\n",
       " 'labore': 16,\n",
       " 'magnam': 13,\n",
       " 'modi': 8,\n",
       " 'neque': 15,\n",
       " 'non': 7,\n",
       " 'numquam': 11,\n",
       " 'porro': 16,\n",
       " 'quaerat': 18,\n",
       " 'quiquia': 21,\n",
       " 'quisquam': 9,\n",
       " 'sed': 4,\n",
       " 'sit': 15,\n",
       " 'tempora': 14,\n",
       " 'ut': 5,\n",
       " 'velit': 20,\n",
       " 'voluptatem': 18}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "wc1 = wordcount(\"sample1.txt\")\n",
    "wc2 = wordcount(\"sample2.txt\")\n",
    "\n",
    "reduce(chain(wc1, wc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.7\n",
    "\n",
    "- Modify the `wordcount` function in order to accept several files as arguments and\n",
    "return the result dict.\n",
    "\n",
    "```\n",
    "wordcount(file1, file2, file3, ...)\n",
    "```\n",
    "\n",
    "[Hint: arbitrary argument lists](https://docs.python.org/3/tutorial/controlflow.html#arbitrary-argument-lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lorem\n",
    "\n",
    "def create_samples(n):\n",
    "    \"\"\"Function create n files with text from lorem package\"\"\"\n",
    "    for i in range(n):\n",
    "        filename = \"sample\" + str(i+1) + \".txt\"\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(lorem.text())\n",
    "\n",
    "create_samples(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adipisci': 27,\n",
       " 'aliquam': 23,\n",
       " 'amet': 27,\n",
       " 'consectetur': 38,\n",
       " 'dolor': 36,\n",
       " 'dolore': 30,\n",
       " 'dolorem': 33,\n",
       " 'eius': 25,\n",
       " 'est': 40,\n",
       " 'etincidunt': 40,\n",
       " 'ipsum': 28,\n",
       " 'labore': 30,\n",
       " 'magnam': 39,\n",
       " 'modi': 35,\n",
       " 'neque': 18,\n",
       " 'non': 33,\n",
       " 'numquam': 37,\n",
       " 'porro': 30,\n",
       " 'quaerat': 32,\n",
       " 'quiquia': 24,\n",
       " 'quisquam': 36,\n",
       " 'sed': 27,\n",
       " 'sit': 28,\n",
       " 'tempora': 27,\n",
       " 'ut': 42,\n",
       " 'velit': 22,\n",
       " 'voluptatem': 28}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wordcount_n_files(*args):\n",
    "    \"\"\"Function that takes n file names as argument\n",
    "    and return a lists containing all words as items in alphabetic order of the n files.\"\"\"\n",
    "    all_words = []\n",
    "    nb_files = len(args)\n",
    "    for i in range(nb_files):\n",
    "        all_words += wordcount(args[i])\n",
    "    return all_words\n",
    "\n",
    "reduce(wordcount_n_files(\"sample1.txt\", \"sample2.txt\", \"sample3.txt\", \"sample4.txt\", \"sample4.txt\"))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample1.txt',\n",
       " 'sample10.txt',\n",
       " 'sample11.txt',\n",
       " 'sample12.txt',\n",
       " 'sample13.txt',\n",
       " 'sample14.txt',\n",
       " 'sample15.txt',\n",
       " 'sample2.txt',\n",
       " 'sample3.txt',\n",
       " 'sample4.txt',\n",
       " 'sample5.txt',\n",
       " 'sample6.txt',\n",
       " 'sample7.txt',\n",
       " 'sample8.txt',\n",
       " 'sample9.txt']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "glob(\"sample*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adipisci': 98,\n",
       " 'aliquam': 93,\n",
       " 'amet': 123,\n",
       " 'consectetur': 109,\n",
       " 'dolor': 123,\n",
       " 'dolore': 101,\n",
       " 'dolorem': 98,\n",
       " 'eius': 97,\n",
       " 'est': 118,\n",
       " 'etincidunt': 105,\n",
       " 'ipsum': 117,\n",
       " 'labore': 104,\n",
       " 'magnam': 110,\n",
       " 'modi': 113,\n",
       " 'neque': 90,\n",
       " 'non': 103,\n",
       " 'numquam': 107,\n",
       " 'porro': 99,\n",
       " 'quaerat': 107,\n",
       " 'quiquia': 101,\n",
       " 'quisquam': 133,\n",
       " 'sed': 127,\n",
       " 'sit': 118,\n",
       " 'tempora': 103,\n",
       " 'ut': 120,\n",
       " 'velit': 96,\n",
       " 'voluptatem': 89}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(wordcount_n_files(*glob(\"sample*.txt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adipisci': 98,\n",
       " 'aliquam': 93,\n",
       " 'amet': 123,\n",
       " 'consectetur': 109,\n",
       " 'dolor': 123,\n",
       " 'dolore': 101,\n",
       " 'dolorem': 98,\n",
       " 'eius': 97,\n",
       " 'est': 118,\n",
       " 'etincidunt': 105,\n",
       " 'ipsum': 117,\n",
       " 'labore': 104,\n",
       " 'magnam': 110,\n",
       " 'modi': 113,\n",
       " 'neque': 90,\n",
       " 'non': 103,\n",
       " 'numquam': 107,\n",
       " 'porro': 99,\n",
       " 'quaerat': 107,\n",
       " 'quiquia': 101,\n",
       " 'quisquam': 133,\n",
       " 'sed': 127,\n",
       " 'sit': 118,\n",
       " 'tempora': 103,\n",
       " 'ut': 120,\n",
       " 'velit': 96,\n",
       " 'voluptatem': 89}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(chain(*[wordcount(file) for file in glob(\"sample*.txt\")]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
